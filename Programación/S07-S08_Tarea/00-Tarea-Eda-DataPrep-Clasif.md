### üìò Actividad Pr√°ctica ‚Äì Preparaci√≥n de Datos y Modelado para Clasificaci√≥n

**Objetivo:**
Aplicar todo el flujo de trabajo de ciencia de datos desde el an√°lisis exploratorio hasta el entrenamiento optimizado de un modelo de clasificaci√≥n, siguiendo el ejemplo trabajado con el dataset *Titanic*.

---

### üìÇ Dataset sugerido: **Bank Marketing (UCI)**

üì• [https://archive.ics.uci.edu/ml/datasets/bank+marketing](https://archive.ics.uci.edu/ml/datasets/bank+marketing)
üìÑ Tambi√©n disponible en Kaggle o con `seaborn` o `openml`.

**Descripci√≥n:**
Datos de una campa√±a de marketing telef√≥nico de una entidad bancaria. El objetivo es predecir si un cliente contratar√° (`y` = "yes"/"no") un dep√≥sito a plazo.

---

### üß© Tareas detalladas

#### 1. **Carga y revisi√≥n inicial**

* Cargar el CSV con `pandas` o `polars`.
* Revisar tipos de datos, n√∫mero de columnas, nulos, valores √∫nicos.

#### 2. **EDA completo**

* Distribuci√≥n de la variable objetivo (`y`) y an√°lisis de balance.
* An√°lisis univariado:

  * Histogramas / countplots para variables num√©ricas y categ√≥ricas.
* An√°lisis bivariado:

  * Boxplots, violinplots, barplots para ver relaciones con `y`.
  * Mapa de calor de correlaci√≥n para variables num√©ricas (`seaborn.heatmap`).
* Detecci√≥n de valores at√≠picos (z-score o IQR si procede).
* Conclusiones intermedias: ¬øQu√© variables parecen relevantes?

#### 3. **Limpieza y transformaci√≥n**

* Conversi√≥n de `y`: `"yes"` ‚Üí `1`, `"no"` ‚Üí `0`.
* Eliminar columnas redundantes si es justificable (como `duration`).
* Revisar y tratar nulos (si los hubiera).
* Crear nuevas variables si es √∫til.

#### 4. **Codificaci√≥n de variables categ√≥ricas**

* One-Hot Encoding para variables nominales.
* Ordinal Encoding si alguna variable tiene orden l√≥gico.
* Justificar cada elecci√≥n.

#### 5. **Escalado de variables num√©ricas**

* Aplicar `StandardScaler`, `MinMaxScaler` o `RobustScaler` si el modelo lo requiere.
* Justificar si escalan y qu√© columnas lo necesitan.

#### 6. **Divisi√≥n del dataset**

* Separar en `X` (features) e `y` (target).
* Usar `train_test_split` con `stratify=y` y `test_size=0.2`.

#### 7. **Entrenamiento inicial de modelos**

* Entrenar al menos 3 modelos diferentes:

  * Ej: `LogisticRegression`, `RandomForestClassifier`, `KNeighborsClassifier`, `SVC`, `XGBClassifier`
* Evaluar con m√©tricas:

  * `accuracy`, `precision`, `recall`, `f1`, `ROC AUC`
* Mostrar matriz de confusi√≥n y curva ROC.

#### 8. **Selecci√≥n del mejor modelo**

* Comparar resultados y justificar cu√°l se adapta mejor seg√∫n las m√©tricas y el objetivo.
* Escoger el mejor para optimizarlo.

#### 9. **Optimizaci√≥n de hiperpar√°metros**

* Aplicar `GridSearchCV` o `RandomizedSearchCV` sobre el modelo seleccionado.
* Mostrar los mejores par√°metros obtenidos.
* Volver a evaluar el modelo optimizado.

#### 10. **Conclusiones finales**

* Comparar el rendimiento antes y despu√©s de la optimizaci√≥n.
* Reflexionar sobre qu√© variables influyeron m√°s, qu√© modelo fue mejor y por qu√©.
* Entregar un resumen con los resultados y gr√°ficos.

---

### üì¶ Entregables

* 1 notebook completo con celdas Markdown explicativas + c√≥digo.
* Archivo `.joblib` o `.parquet` con datos preparados (opcional).
* Gr√°ficos generados durante el EDA y evaluaci√≥n de modelos.
* Conclusi√≥n final bien redactada.

---

### üìä Evaluaci√≥n (r√∫brica)

| Criterio                           | Peso |
| ---------------------------------- | ---- |
| An√°lisis exploratorio completo     | 25%  |
| Preprocesamiento y codificaci√≥n    | 15%  |
| Entrenamiento y evaluaci√≥n inicial | 20%  |
| Optimizaci√≥n y modelo final        | 20%  |
| Presentaci√≥n y justificaci√≥n final | 20%  |

---
¬°Buena suerte y disfruta del proceso de ciencia de datos completo! üöÄ